services:
  datadog_api:
    build:
      context: ./datadog_api_sample
    ports:
      - "8080:8080"
    env_file:
      - .env
    volumes:
      - ./datadog_api_sample:/app
    restart: unless-stopped

  ollama:
    image: ollama/ollama:latest
    ports:
      - "11434:11434"
    volumes:
      - ./ollama-data:/root/.ollama
    restart: unless-stopped
    healthcheck:
      test: ["CMD-SHELL", "ollama list >/dev/null 2>&1 || exit 1"]
      interval: 5s
      timeout: 3s
      retries: 40

  ollama-init:
    image: ollama/ollama:latest
    depends_on:
      ollama:
        condition: service_healthy
    env_file:
      - .env
    volumes:
      - ./ollama-data:/root/.ollama
    entrypoint: ["/bin/sh", "-lc"]
    command:
      - |
        set -e
        echo "[ollama-init] model=${OLLAMA_MODEL}"
        # 서버 준비 대기(짧게)
        for i in 1 2 3 4 5 6 7 8 9 10; do
          ollama list >/dev/null 2>&1 && break || true
          echo "[ollama-init] waiting for ollama..."
          sleep 1
        done
        echo "[ollama-init] pulling..."
        ollama pull "${OLLAMA_MODEL}"
        echo "[ollama-init] done"
    restart: "no"

  mcp_agent:
    build:
      context: ./mcp_agent
    depends_on:
      ollama-init:
        condition: service_completed_successfully
      datadog_api:
        condition: service_started
    ports:
      - "8090:8090"
    env_file:
      - .env
    restart: unless-stopped
